{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_TARGETS = [f\"{_} wk ahead inc death\" for _ in range(1, 5)] + \\\n",
    "                [f\"{_} wk ahead cum death\" for _ in range(1, 5)] + \\\n",
    "                [f\"{_} wk ahead inc case\" for _ in range(1, 5)]\n",
    "\n",
    "MODELS_TO_EXCLUDE = ['COVIDhub-ensemble', 'COVIDhub-trained_ensemble', \n",
    "                     'CU-nochange', 'CU-scenario_high', 'CU-scenario_low', 'CU-scenario_mid',\n",
    "                     'KITmetricslab-select_ensemble']\n",
    "\n",
    "LOCATIONS_TO_EXCLUDE = [\"11\", \"60\", \"66\", \"69\", \"72\", \"74\", \"78\"]\n",
    "\n",
    "# DC,11,District of Columbia\n",
    "# AS,60,American Samoa\n",
    "# GU,66,Guam\n",
    "# MP,69,Northern Mariana Islands\n",
    "# PR,72,Puerto Rico\n",
    "# UM,74,U.S. Minor Outlying Islands\n",
    "# VI,78,Virgin Islands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_monday(date):\n",
    "    return pd.date_range(start=date, end=date + pd.offsets.Day(6), freq='W-MON')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_filepaths_and_dates(models_to_exclude, online=False):\n",
    "    if online:\n",
    "        url = \"https://api.github.com/repos/reichlab/covid19-forecast-hub/git/trees/master?recursive=1\"\n",
    "        r = requests.get(url)\n",
    "        res = r.json()\n",
    "\n",
    "        files = [file[\"path\"] for file in res[\"tree\"] if (file[\"path\"].startswith('data-processed/') and file[\"path\"].endswith('.csv'))]\n",
    "    else:\n",
    "        files = glob.glob('../covid19-forecast-hub/data-processed/**/*.csv', recursive=True)\n",
    "        files = [f.replace('../covid19-forecast-hub/', '').replace('\\\\', '/') for f in files]\n",
    "\n",
    "    df_files = pd.DataFrame({'filename':files})\n",
    "\n",
    "    df_files['model'] = df_files.filename.apply(lambda f: f.split('/')[1])\n",
    "\n",
    "    df_files['forecast_date'] = df_files.filename.apply(lambda f: f.split('/')[2][:10])\n",
    "    df_files.forecast_date = pd.to_datetime(df_files.forecast_date)\n",
    "\n",
    "    df_files['timezero'] = df_files.forecast_date.apply(next_monday)\n",
    "\n",
    "    df_files = df_files[~df_files.model.isin(models_to_exclude)]\n",
    "    \n",
    "    df_files.sort_values('filename', inplace=True, ignore_index=True)\n",
    "\n",
    "    return df_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_files = get_all_filepaths_and_dates(MODELS_TO_EXCLUDE, online=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_submissions(df, locations_to_exclude, train_set = True):\n",
    "    # only consider US + 50 states\n",
    "    df = df[df.location.str.len() == 2]\n",
    "    df = df[~df.location.isin(locations_to_exclude)]\n",
    "\n",
    "    df = df[df.type == 'quantile']\n",
    "    df.dropna(subset = ['value'], inplace = True)\n",
    "    \n",
    "    if train_set:\n",
    "        # how many forecasts for each target/model/location? should be 4 for every location\n",
    "        df['no_forecasts'] = df.groupby(['target', 'model', 'location'])['target_end_date'].transform('nunique')\n",
    "        df = df[df.groupby(['target', 'model'])['no_forecasts'].transform('min') == 4].drop(columns='no_forecasts').reset_index(drop=True)\n",
    "\n",
    "    df['no_quantiles'] = df.groupby(['model', 'target', 'target_end_date', 'location'])['quantile'].transform('nunique')\n",
    "    df['no_quantiles'] = df.groupby(['target', 'model'])['no_quantiles'].transform('min')\n",
    "\n",
    "    df = df[(df.no_quantiles == 23) | \n",
    "            (df.target.str.contains('inc case') & (df.no_quantiles == 7))].drop(columns='no_quantiles').reset_index(drop=True)\n",
    "\n",
    "    # ensure that for all targets each model provides forecasts for all locations\n",
    "    df = df[df.groupby(['target', 'model'])['location'].transform('nunique') == 51]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(files, test_date, valid_targets, locations_to_exclude, online=False):\n",
    "    test_date = pd.to_datetime(test_date)\n",
    "    df_test_files = files[files.timezero == test_date]\n",
    "    \n",
    "    if online:\n",
    "        base_path = 'https://github.com/reichlab/covid19-forecast-hub/raw/master/'\n",
    "    else:\n",
    "        base_path = '../covid19-forecast-hub/'\n",
    "    \n",
    "    dfs = []\n",
    "    for _, row in tqdm(df_test_files.iterrows(), total=df_test_files.shape[0], desc = 'Load test data'):\n",
    "        df_temp = pd.read_csv(base_path + row['filename'],\n",
    "                              dtype = {'target': str, 'location': str, 'type': str, 'quantile': float, 'value': float}, \n",
    "                              parse_dates = ['forecast_date', 'target_end_date'])\n",
    "        df_temp = df_temp[df_temp.target.isin(VALID_TARGETS)]\n",
    "        df_temp['model'] = row['model']\n",
    "        dfs.append(df_temp)\n",
    "    df_test = pd.concat(dfs)\n",
    "    \n",
    "    df_test = validate_submissions(df_test, locations_to_exclude, train_set = False)\n",
    "    \n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = load_test_data(df_files, '2021-06-14', VALID_TARGETS, LOCATIONS_TO_EXCLUDE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d - 4 weeks - (horizon - 1) --> end: d - horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forecast_dates_by_horizon(test_date, window_size = 4):\n",
    "    # assigns to each horizon the corresponding training forecast dates for the test date\n",
    "    forecast_dates_by_horizon = {}\n",
    "    for horizon in range(1, 5):\n",
    "        forecast_dates_by_horizon[horizon] = [test_date - pd.Timedelta(weeks = window_size) - pd.Timedelta(weeks = (horizon - 1)), \n",
    "                     test_date - pd.Timedelta(weeks = horizon)]\n",
    "    return forecast_dates_by_horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_horizons(forecast_date, forecast_dates_by_horizon):\n",
    "    relevant_horizons = []\n",
    "    for horizon in range(1, 5):\n",
    "        if((forecast_date >= forecast_dates_by_horizon[horizon][0]) & (forecast_date <= forecast_dates_by_horizon[horizon][1])):\n",
    "            relevant_horizons.append(horizon)\n",
    "    return relevant_horizons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data(files, test_date, valid_targets, locations_to_exclude, window_size = 4, online = False):\n",
    "    test_date = pd.to_datetime(test_date)\n",
    "    lower_bound = test_date - pd.Timedelta(weeks = window_size) - pd.Timedelta(weeks=(window_size - 1))\n",
    "    df_train_files = files[(files.timezero >= lower_bound) & (files.timezero < test_date)].copy()\n",
    "    \n",
    "    forecast_dates_by_horizon = get_forecast_dates_by_horizon(test_date, window_size)\n",
    "    df_train_files['horizons'] = df_train_files.timezero.apply(get_relevant_horizons, \n",
    "                                                               forecast_dates_by_horizon=forecast_dates_by_horizon)\n",
    "    \n",
    "    if online:\n",
    "        base_path = 'https://github.com/reichlab/covid19-forecast-hub/raw/master/'\n",
    "    else:\n",
    "        base_path = '../covid19-forecast-hub/'\n",
    "    \n",
    "    dfs = []\n",
    "    for _, row in tqdm(df_train_files.iterrows(), total=df_train_files.shape[0], desc = 'Load train data'):\n",
    "        relevant_targets = [f\"{_} wk ahead inc death\" for _ in row['horizons']] + \\\n",
    "                           [f\"{_} wk ahead cum death\" for _ in row['horizons']] + \\\n",
    "                           [f\"{_} wk ahead inc case\" for _ in row['horizons']]\n",
    "        df_temp = pd.read_csv(base_path + row['filename'],\n",
    "                              dtype = {'target': str, 'location': str, 'type': str, 'quantile': float, 'value': float}, \n",
    "                              parse_dates = ['forecast_date', 'target_end_date'])\n",
    "        df_temp = df_temp[df_temp.target.isin(relevant_targets)]\n",
    "        df_temp['model'] = row['model']\n",
    "        dfs.append(df_temp)\n",
    "    df_train = pd.concat(dfs)\n",
    "    \n",
    "    df_train = validate_submissions(df_train, locations_to_exclude, train_set = True)\n",
    "    \n",
    "    return df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = load_train_data(df_files, '2021-06-14', VALID_TARGETS, LOCATIONS_TO_EXCLUDE, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_test(test_date, valid_targets, locations_to_exclude, models_to_exclude, window_size = 4, online = False):\n",
    "    files = get_all_filepaths_and_dates(models_to_exclude)\n",
    "    \n",
    "    df_test = load_test_data(files, test_date, valid_targets, locations_to_exclude, online)\n",
    "    df_train = load_train_data(files, test_date, valid_targets, locations_to_exclude, window_size, online)\n",
    "    \n",
    "    # dicts of the models available for each target\n",
    "    available_models_test  = dict(df_test.groupby(['target'])['model'].unique())\n",
    "    available_models_train = dict(df_train.groupby(['target'])['model'].unique())\n",
    "    \n",
    "    # ensure models are available in both train and test set\n",
    "    df_train = df_train[df_train.apply(lambda x: x.model in (available_models_test[x.target]), axis=1)]\n",
    "    df_test  = df_test[df_test.apply(lambda x: x.model in (available_models_train[x.target]), axis=1)]\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train, df_test = load_train_test('2021-06-14', VALID_TARGETS, LOCATIONS_TO_EXCLUDE, MODELS_TO_EXCLUDE, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_train_test_sets(test_dates, valid_targets, locations_to_exclude, models_to_exclude, window_size = 4, online = False):\n",
    "    for test_date in test_dates:\n",
    "        print(test_date)\n",
    "        df_train, df_test = load_train_test(test_date, valid_targets, locations_to_exclude, models_to_exclude, \n",
    "                                            window_size, online)\n",
    "        df_train.to_csv(f'data/{test_date.date()}_train.csv', index=False)\n",
    "        df_test.to_csv(f'data/{test_date.date()}_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# compute_train_test_sets(['2021-06-07', '2021-06-14'], VALID_TARGETS, LOCATIONS_TO_EXCLUDE, MODELS_TO_EXCLUDE, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dates = pd.date_range('2021-05-17', '2021-08-09', freq='W-MON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-17 00:00:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc1723d221149bc8ed115299e39f1ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load test data:   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8199e622b904791abc67b8d8f30e701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load train data:   0%|          | 0/416 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-24 00:00:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f83612a5a95242e5bb355987eaa8a1d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load test data:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173e136e6b0b4143ab2a80faac036397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load train data:   0%|          | 0/413 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-31 00:00:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad3dca5736c04fb5be32f739007417cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load test data:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a942da20378749c58c2fa501db8740bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load train data:   0%|          | 0/407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-07 00:00:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b376f31d6e74953a3fbb13d6f2c8a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load test data:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c2f530b1a9c40f99549973c2a08b416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load train data:   0%|          | 0/405 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-14 00:00:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9f63ab619045c0addc6941b6218196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load test data:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e5436fb51184e4c9230fc8a56a379af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load train data:   0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-21 00:00:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e70b9e7fb6b6412f8edc0dd56ba07223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load test data:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51fb47907bf047088d321f3b7c7c426a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load train data:   0%|          | 0/387 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-28 00:00:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09595f3100344ccc8a4ad988a26599fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load test data:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074ff4daab2b4de4bb2d2e5bf2f60183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load train data:   0%|          | 0/384 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-05 00:00:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a622b149b64b3ca79226d66ba1ace3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load test data:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03482d318cb04e1c9bd60ccef2a4e631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load train data:   0%|          | 0/374 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-12 00:00:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b81416f7ef4f6089788855b9b544fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load test data:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf74d6972f6648b49d42927247577af3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load train data:   0%|          | 0/368 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-19 00:00:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3dc1358804b4f5ebf26ad6c3a82b00f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load test data:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e11c2372494fb298a3f0f3fbcbcc26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load train data:   0%|          | 0/363 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-26 00:00:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ccff3b4a5924a45b6b862052e70b3c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load test data:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09172258dab44f7b9548bb59d04db2a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load train data:   0%|          | 0/358 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-02 00:00:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91bc6f3c5f494cbe9d3a4cb2e8598ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load test data:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9bb071298d54e8fa93743ce19b2d1c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load train data:   0%|          | 0/358 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-09 00:00:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac07e3ca050649b0b2badf85f0c125ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load test data:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e81c98960af94a58ac51c4e855ebf182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load train data:   0%|          | 0/353 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compute_train_test_sets(test_dates, VALID_TARGETS, LOCATIONS_TO_EXCLUDE, MODELS_TO_EXCLUDE, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
